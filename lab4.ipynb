{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratory 4: Reinforcement learning\n",
    "\n",
    "In the end of the lab, you should export the notebook to a Python script (File >> Download as >> Python (.py)). Your file should be named `padi-lab4-groupXX.py`, where the `XX` corresponds to your group number and should be submitted to the e-mail <adi.tecnico@gmail.com>. \n",
    "\n",
    "Make sure...\n",
    "\n",
    "* **... that the subject is of the form `[<group n.>] LAB <lab n.>`.** \n",
    "\n",
    "* **... to strictly respect the specifications in each activity, in terms of the intended inputs, outputs and naming conventions.** \n",
    "\n",
    "In particular, after completing the activities you should be able to replicate the examples provided (although this, in itself, is no guarantee that the activities are correctly completed).\n",
    "\n",
    "### 1. The MDP Model \n",
    "\n",
    "In this lab you will implement several reinforcement learning algorithms, and use the \"Pacman\" domain, from Lab 2, to test and compare these algorithms. Don't forget, however, that your functions should work for **any MDP** and not just the one provided. \n",
    "\n",
    "The \"Pacman\" domain to be used is represented in the diagram below.\n",
    "\n",
    "<img src=\"pacman-big.png\">\n",
    "\n",
    "In the Pacman domain above,\n",
    "\n",
    "* The ghost moves randomly between cells 1-3.\n",
    "* The player controls the movement of Pacman through four actions: `Up`, `Down`, `Left`, and `Right`. \n",
    "* Each action moves the Pacman character one step in the corresponding direction, if an adjacent cell exists in that direction. Otherwise, Pacman remains in the same place.\n",
    "* The cell in the bottom left corner (cell `29`) is adjacent, to the left, to the cell in the bottom right corner (cell `35`). In other words, if Pacman \"moves left\" in cell `29` it will end up in cell `35` and vice-versa.\n",
    "* If Pacman lies in the same cell as the ghost (in either cell `1`, `2`, or `3`), the player loses the game. However, if Pacman \"eats\" the blue pellet (in cell `24`), it gains the ability to \"eat\" the ghost. In this case, if Pacman lies in the same cell as the ghost, it \"eats\" the ghost and wins the game. Assume that Pacman can never be in cell `24` without \"eating\" the pellet.\n",
    "\n",
    "**Throughout the lab, unless if stated otherwise, use $\\gamma=0.9$.**\n",
    "\n",
    "$$\\diamond$$\n",
    "\n",
    "We start by loading the MDP for the \"Pacman\" domain from the file `pacman.npz`. We will use this domain as an example to illustrate the different functions/algorithms you are expected to deploy. The file contains both the MDP, described as a tuple like those from Lab 2, and the corresponding optimal $Q$-function.\n",
    "\n",
    "To do so, you can run the code\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "mdp_info = np.load('pacman.npz', allow_pickle=True)\n",
    "\n",
    "# The MDP is a tuple (X, A, P, c, gamma)\n",
    "M = mdp_info['M']\n",
    "\n",
    "# We also load the optimal Q-function for the MDP\n",
    "Qopt = mdp_info['Q']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "In the first activity, you will implement a \"simulator of the world\". The simulator consists of a function that enables you to sample a transition from a given MDP. You will then use this function, in subsequent activities, to generate the data that your agent will use to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mdp_info = np.load('pacman.npz', allow_pickle=True)\n",
    "\n",
    "# The MDP is a tuple (X, A, P, c, gamma)\n",
    "M = mdp_info['M']\n",
    "\n",
    "# We also load the optimal Q-function for the MDP\n",
    "Qopt = mdp_info['Q']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 1.        \n",
    "\n",
    "Write a function named `sample_transition` that receives, as input, a tuple representing an arbitrary MDP as well as two integers, `s` and `a`, corresponding to a state and an action. The function should return a tuple `(s, a, c, s')`, where `c` is the cost associated with performing action `a` in state `s` and `s'` is a state generated from `s` upon selecting action `a`, according to the transition probabilities for the MDP.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T09:18:48.272364Z",
     "start_time": "2019-12-09T09:18:48.264410Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert your code here.\n",
    "def sample_transition(mdp, s, a):\n",
    "    \n",
    "    # cost associated with performing action a\n",
    "    c = mdp[3][s,a]\n",
    "    \n",
    "    # trasition probability matrix associated with action a \n",
    "    Pa = mdp[2][a]\n",
    "    \n",
    "    # generate s', given the probability distribution at state x upon selecting action a\n",
    "    next_state = rnd.choice(len(mdp[0]), p=Pa[s, :])\n",
    "    \n",
    "    return (s,a,c,next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed transition:\n",
      "((18, 0, 2), Left, 0.1, (17, 0, 3))\n",
      "\n",
      "Observed transition:\n",
      "((3, S, 1), Left, 0.1, (2, S, 2))\n",
      "\n",
      "Observed transition:\n",
      "((28, 0, 3), Up, 0.1, (24, S, 2))\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as rnd\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "# Select random state and action\n",
    "s = 106 # State (18, 0, 2)\n",
    "a = rnd.randint(len(M[1]))\n",
    "\n",
    "s, a, cnew, snew = sample_transition(M, s, a)\n",
    "\n",
    "print('Observed transition:\\n(', end='')\n",
    "print(M[0][s], end=', ')\n",
    "print(M[1][a], end=', ')\n",
    "print(cnew, end=', ')\n",
    "print(M[0][snew], end=')\\n')\n",
    "\n",
    "# Select random state and action\n",
    "s = 12 # State (3, S, 1)\n",
    "a = rnd.randint(len(M[1]))\n",
    "\n",
    "s, a, cnew, snew = sample_transition(M, s, a)\n",
    "\n",
    "print('\\nObserved transition:\\n(', end='')\n",
    "print(M[0][s], end=', ')\n",
    "print(M[1][a], end=', ')\n",
    "print(cnew, end=', ')\n",
    "print(M[0][snew], end=')\\n')\n",
    "\n",
    "# Select random state and action\n",
    "s = 164 # State (28, 0, 3)\n",
    "a = rnd.randint(len(M[1]))\n",
    "\n",
    "s, a, cnew, snew = sample_transition(M, s, a)\n",
    "\n",
    "print('\\nObserved transition:\\n(', end='')\n",
    "print(M[0][s], end=', ')\n",
    "print(M[1][a], end=', ')\n",
    "print(cnew, end=', ')\n",
    "print(M[0][snew], end=')\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All reinforcement learning algorithms that you will implement can only access the MDP through the function `sample_transition` which, in a sense, simulates an \"interaction\" of the agent with the environment.\n",
    "\n",
    "For example, using the \"Pacman\" MDP, you could run:\n",
    "\n",
    "```python\n",
    "import numpy.random as rnd\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "# Select random state and action\n",
    "s = 106 # State (18, 0, 2)\n",
    "a = rnd.randint(len(M[1]))\n",
    "\n",
    "s, a, cnew, snew = sample_transition(M, s, a)\n",
    "\n",
    "print('Observed transition:\\n(', end='')\n",
    "print(M[0][s], end=', ')\n",
    "print(M[1][a], end=', ')\n",
    "print(cnew, end=', ')\n",
    "print(M[0][snew], end=')\\n')\n",
    "\n",
    "# Select random state and action\n",
    "s = 12 # State (3, S, 1)\n",
    "a = rnd.randint(len(M[1]))\n",
    "\n",
    "s, a, cnew, snew = sample_transition(M, s, a)\n",
    "\n",
    "print('\\nObserved transition:\\n(', end='')\n",
    "print(M[0][s], end=', ')\n",
    "print(M[1][a], end=', ')\n",
    "print(cnew, end=', ')\n",
    "print(M[0][snew], end=')\\n')\n",
    "\n",
    "# Select random state and action\n",
    "s = 164 # State (28, 0, 3)\n",
    "a = rnd.randint(len(M[1]))\n",
    "\n",
    "s, a, cnew, snew = sample_transition(M, s, a)\n",
    "\n",
    "print('\\nObserved transition:\\n(', end='')\n",
    "print(M[0][s], end=', ')\n",
    "print(M[1][a], end=', ')\n",
    "print(cnew, end=', ')\n",
    "print(M[0][snew], end=')\\n')\n",
    "```\n",
    "\n",
    "and get, as output:\n",
    "\n",
    "```\n",
    "Observed transition:\n",
    "((18, 0, 2), Left, 0.1, (17, 0, 3))\n",
    "\n",
    "Observed transition:\n",
    "((3, S, 1), Left, 0.1, (2, S, 2))\n",
    "\n",
    "Observed transition:\n",
    "((28, 0, 3), Up, 0.1, (24, S, 2))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 2.        \n",
    "\n",
    "Write down a function named `egreedy` that implements an $\\epsilon$-greedy policy. Your function should receive, as input, a `numpy` array `Q` with shape `(N,)`, for some integer `N`, and, as an optional argument, a floating point number `eps` with a default value `eps=0.1`. Your function should return... \n",
    "\n",
    "* ... with a probability $\\epsilon$, a random index between $0$ and $N-1$.\n",
    "* ... with a probability $1-\\epsilon$, the index between $0$ and $N-1$ corresponding to the minimum value of `Q`. If more than one such index exists, the function should select among such indices **uniformly at random**.\n",
    "\n",
    "**Note:** In the upcoming activities, the array `Q` received by the function `egreedy` will correspond to a row of a $Q$-function, and `N` will correspond to the number of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T09:18:48.301639Z",
     "start_time": "2019-12-09T09:18:48.296224Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here.\n",
    "def egreedy(Q, eps = 0.1):\n",
    "    \n",
    "    N = Q.shape[0]\n",
    "    \n",
    "    # uniform distribution over the interval [0,1]\n",
    "    p = rnd.uniform()\n",
    "    \n",
    "    if p < eps: # exploration \n",
    "        a = rnd.choice(N)\n",
    "        \n",
    "    else: # explotation \n",
    "        a_greedy = np.isclose(Q, np.min(Q)).astype(int)\n",
    "        \n",
    "        # uniform distribution over the actions that have associated the minimum value of Q. \n",
    "        # The other actions have a probability of 0 \n",
    "        distr = a_greedy/a_greedy.sum()\n",
    "        \n",
    "        a = rnd.choice(N, p = distr.flatten())\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: (18, 0, 2) - action (eps=0.0): Right\n",
      "State: (18, 0, 2) - action (eps=0.5): Right\n",
      "State: (18, 0, 2) - action (eps=1.0): Left\n",
      "\n",
      "State: (3, S, 1) - action (eps=0.0): Left\n",
      "State: (3, S, 1) - action (eps=0.5): Right\n",
      "State: (3, S, 1) - action (eps=1.0): Down\n",
      "\n",
      "State: (28, 0, 3) - action (eps=0.0): Up\n",
      "State: (28, 0, 3) - action (eps=0.5): Up\n",
      "State: (28, 0, 3) - action (eps=1.0): Up\n"
     ]
    }
   ],
   "source": [
    "rnd.seed(42)\n",
    "\n",
    "s = 106 # State (18, 0, 2)\n",
    "a = egreedy(Qopt[s, :], eps=0)\n",
    "print('State:', M[0][s], '- action (eps=0.0):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=0.5)\n",
    "print('State:', M[0][s], '- action (eps=0.5):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=1.0)\n",
    "print('State:', M[0][s], '- action (eps=1.0):', M[1][a])\n",
    "\n",
    "s = 12 # State (3, S, 1)\n",
    "a = egreedy(Qopt[s, :], eps=0)\n",
    "print('\\nState:', M[0][s], '- action (eps=0.0):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=0.5)\n",
    "print('State:', M[0][s], '- action (eps=0.5):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=1.0)\n",
    "print('State:', M[0][s], '- action (eps=1.0):', M[1][a])\n",
    "\n",
    "s = 164 # State (28, 0, 3)\n",
    "a = egreedy(Qopt[s, :], eps=0)\n",
    "print('\\nState:', M[0][s], '- action (eps=0.0):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=0.5)\n",
    "print('State:', M[0][s], '- action (eps=0.5):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=1.0)\n",
    "print('State:', M[0][s], '- action (eps=1.0):', M[1][a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, using the function `Qopt` loaded from the \"Pacman\" file, you can run:\n",
    "\n",
    "```python\n",
    "rnd.seed(42)\n",
    "\n",
    "s = 106 # State (18, 0, 2)\n",
    "a = egreedy(Qopt[s, :], eps=0)\n",
    "print('State:', M[0][s], '- action (eps=0.0):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=0.5)\n",
    "print('State:', M[0][s], '- action (eps=0.5):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=1.0)\n",
    "print('State:', M[0][s], '- action (eps=1.0):', M[1][a])\n",
    "\n",
    "s = 12 # State (3, S, 1)\n",
    "a = egreedy(Qopt[s, :], eps=0)\n",
    "print('\\nState:', M[0][s], '- action (eps=0.0):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=0.5)\n",
    "print('State:', M[0][s], '- action (eps=0.5):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=1.0)\n",
    "print('State:', M[0][s], '- action (eps=1.0):', M[1][a])\n",
    "\n",
    "s = 164 # State (28, 0, 3)\n",
    "a = egreedy(Qopt[s, :], eps=0)\n",
    "print('\\nState:', M[0][s], '- action (eps=0.0):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=0.5)\n",
    "print('State:', M[0][s], '- action (eps=0.5):', M[1][a])\n",
    "a = egreedy(Qopt[s, :], eps=1.0)\n",
    "print('State:', M[0][s], '- action (eps=1.0):', M[1][a])\n",
    "```\n",
    "\n",
    "you will get the output\n",
    "\n",
    "```\n",
    "State: (18, 0, 2) - action (eps=0.0): Right\n",
    "State: (18, 0, 2) - action (eps=0.5): Right\n",
    "State: (18, 0, 2) - action (eps=1.0): Left\n",
    "\n",
    "State: (3, S, 1) - action (eps=0.0): Left\n",
    "State: (3, S, 1) - action (eps=0.5): Right\n",
    "State: (3, S, 1) - action (eps=1.0): Down\n",
    "\n",
    "State: (28, 0, 3) - action (eps=0.0): Up\n",
    "State: (28, 0, 3) - action (eps=0.5): Up\n",
    "State: (28, 0, 3) - action (eps=1.0): Up\n",
    "```\n",
    "\n",
    "Note that, depending on the order and number of calls to functions in the random library you may get slightly different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 3. \n",
    "\n",
    "Write a function `mb_learning` that implements the model-based reinforcement learning algorithm discussed in class. Your function should receive as input arguments \n",
    "\n",
    "* A tuple, `mdp`, containing the description of an **arbitrary** MDP. The structure of the tuple is similar to that provided in the example above. \n",
    "* An integer, `n`, corresponding the number of steps that your algorithm should run.\n",
    "*  A numpy array `qinit` with as many rows as the number of states in `mdp` and as many columns as the number of actions in `mdp`. The matrix `qinit` should be used to initialize the $Q$-function being learned by your function.\n",
    "* A tuple, `Pinit`, with as many elements as the number of actions in `mdp`. Each element of `Pinit` corresponds to square numpy arrays with as many rows/columns as the number of states in `mdp` and can be **any** transition probability matrix. The matrices in `Pinit` should be used to initialize the transition probability matrices of the model being learned by your function.\n",
    "* A numpy array `cinit` with as many rows as the number of states in `mdp` and as many columns as the number of actions in `mdp`. The matrix `cinit` should be used to initialize the cost function of the model being learned by your function.\n",
    "\n",
    "Your function should simulate an interaction of `n` steps between the agent and the environment, during which it should perform `n` iterations of the model-based RL algorithm seen in class. In particular, it should learn the transition probabilities and cost function from the interaction between the agent and the environment, and use these to compute the optimal $Q$-function. The transition probabilities, cost and $Q$-functions to be learned should be initialized using `Pinit`, `cinit` and `qinit`, respectively. \n",
    "\n",
    "Note that, at each step of the interaction,\n",
    "\n",
    "* The agent should observe the current state, and select an action using an $\\epsilon$-greedy policy with respect to its current estimate of the optimal $Q$-values. You should use the function `egreedy` from Activity 2, with $\\epsilon=0.15$. \n",
    "* Given the state and action, you must then compute the cost and generate the next state, using `mdp` and the function `sample_transition` from Activity 1.\n",
    "* With this transition information (state, action, cost, next-state), you can now perform an update to the transition probabilities, cost function, and $Q$-function.\n",
    "* When updating the components $(x,a)$ of the model, use the step-size\n",
    "\n",
    "$$\\alpha_t=\\frac{1}{N_t(x,a)+1},$$\n",
    "\n",
    "where $N_t(x,a)$ is the number of visits to the pair $(x,a)$ up to time step $t$.\n",
    "\n",
    "Your function should return a tuple containing:\n",
    "\n",
    "*  A numpy array with as many rows as the number of states in `mdp` and as many columns as the number of actions in `mdp`, corresponding to the learned $Q$-function.\n",
    "* A tuple with as many elements as the number of actions in `mdp`. The element $a$ of the tuple corresponds to a square numpy array with as many rows/columns as the number of states in `mdp`, corresponding to the learned transition probabilities for action $a$.\n",
    "* A numpy array with as many rows as the number of states in `mdp` and as many columns as the number of actions in `mdp`, corresponding to the learned cost function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T09:18:48.330597Z",
     "start_time": "2019-12-09T09:18:48.322311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here.\n",
    "def mb_learning(mdp, n, qinit, Pinit, cinit):\n",
    "    \n",
    "    # initialization of the number of visits to the pair (ð‘¥,ð‘Ž) up to time step ð‘¡\n",
    "    N = np.ones((len(mdp[0]), len(mdp[1])))\n",
    "    \n",
    "    gamma = mdp[-1]\n",
    "    \n",
    "    numstates = len(mdp[0])\n",
    "    numactions = len(mdp[1])\n",
    "    \n",
    "    # select at random the initial state (time step t = 0)\n",
    "    s = rnd.choice(numstates)\n",
    "    \n",
    "    # simulates an interaction of n steps between the agent and the environment\n",
    "    for t in range(n):\n",
    "        \n",
    "        # given the current state, select an action using an ðœ–-greedy policy with respect to \n",
    "        # its current estimate of the optimal ð‘„-values\n",
    "        a = egreedy(qinit[s,:], 0.15) \n",
    "        \n",
    "        # update the number of visits to the pair (ð‘¥,ð‘Ž) up to time step ð‘¡\n",
    "        N[s,a] += 1\n",
    "        \n",
    "        # step-size\n",
    "        alfa = 1/(N[s,a])\n",
    "        \n",
    "        \n",
    "        # compute the cost and generate the next state\n",
    "        transition = sample_transition(mdp, s, a)\n",
    "        \n",
    "        # cost in time step t\n",
    "        c = transition[2]\n",
    "        \n",
    "        # state in time step t + 1\n",
    "        s_next = transition[3]\n",
    "        \n",
    "        \n",
    "        # perform an update to the transition probabilities, cost function, and ð‘„-function.\n",
    "        cinit[s,a] += alfa*(c - cinit[s,a])\n",
    "        \n",
    "        I = np.zeros((numstates,1))\n",
    "        I[s_next,0]=1\n",
    "        \n",
    "        Pinit[a][s,:] += alfa*(I.flatten()-Pinit[a][s,:])\n",
    "        \n",
    "        qinit[s,a] = cinit[s,a] + gamma*((Pinit[a][s, :]).dot(np.min(qinit, axis = 1)))\n",
    "        \n",
    "        # update the current state for the next iteration \n",
    "        s = s_next \n",
    "        \n",
    "    return (qinit, Pinit, cinit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Q after 1000 steps: 19.916238521031588\n",
      "Error in Q after 2000 steps: 19.864356679803585\n"
     ]
    }
   ],
   "source": [
    "rnd.seed(42)\n",
    "\n",
    "# Initialize transition probabilities\n",
    "pinit = ()\n",
    "\n",
    "for a in range(len(M[1])):\n",
    "    pinit += (np.eye(len(M[0])),)\n",
    "\n",
    "# Initialize cost function\n",
    "cinit = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "# Initialize Q-function\n",
    "qinit = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "# Run 1000 steps of model-based learning\n",
    "qnew, pnew, cnew = mb_learning(M, 1000, qinit, pinit, cinit)\n",
    "\n",
    "# Compare the learned Q with the optimal Q\n",
    "print('Error in Q after 1000 steps:', np.linalg.norm(qnew - Qopt))\n",
    "\n",
    "# Run 1000 additional steps of model-based learning\n",
    "qnew, pnew, cnew = mb_learning(M, 1000, qnew, pnew, cnew)\n",
    "\n",
    "# Compare once again the learned Q with the optimal Q\n",
    "print('Error in Q after 2000 steps:', np.linalg.norm(qnew - Qopt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T09:18:48.567188Z",
     "start_time": "2019-12-09T09:18:48.333226Z"
    },
    "scrolled": false
   },
   "source": [
    "As an example using the \"Pacman\" MDP, we could run:\n",
    "\n",
    "```python\n",
    "rnd.seed(42)\n",
    "\n",
    "# Initialize transition probabilities\n",
    "pinit = ()\n",
    "\n",
    "for a in range(len(M[1])):\n",
    "    pinit += (np.eye(len(M[0])),)\n",
    "\n",
    "# Initialize cost function\n",
    "cinit = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "# Initialize Q-function\n",
    "qinit = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "# Run 1000 steps of model-based learning\n",
    "qnew, pnew, cnew = mb_learning(M, 1000, qinit, pinit, cinit)\n",
    "\n",
    "# Compare the learned Q with the optimal Q\n",
    "print('Error in Q after 1000 steps:', np.linalg.norm(qnew - Qopt))\n",
    "\n",
    "# Run 1000 additional steps of model-based learning\n",
    "qnew, pnew, cnew = mb_learning(M, 1000, qnew, pnew, cnew)\n",
    "\n",
    "# Compare once again the learned Q with the optimal Q\n",
    "print('Error in Q after 2000 steps:', np.linalg.norm(qnew - Qopt))\n",
    "```\n",
    "\n",
    "to get\n",
    "\n",
    "```\n",
    "Error in Q after 1000 steps: 19.916238521031588\n",
    "Error in Q after 2000 steps: 19.86435667980359\n",
    "```\n",
    "\n",
    "Note that, even if the seed is fixed, the numerical values may differ somewhat from those above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model-free learning\n",
    "\n",
    "You will now implement both $Q$-learning and SARSA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 4. \n",
    "\n",
    "Write a function `qlearning` that implements the $Q$-learning algorithm discussed in class. Your function should receive as input arguments \n",
    "\n",
    "* A tuple, `mdp`, containing the description of an **arbitrary** MDP. The structure of the tuple is similar to that provided in the examples above. \n",
    "* An integer, `n`, corresponding he number of steps that your algorithm should run.\n",
    "*  A `numpy` array `qinit` with as many rows as the number of states in `mdp` and as many columns as the number of actions in `mdp`. The matrix `qinit` should be used to initialize the $Q$-function being learned by your function.\n",
    "\n",
    "Your function should simulate an interaction of `n` steps between the agent and the environment, during which it should perform `n` iterations of the $Q$-learning algorithm seen in class. In particular, it should learn optimal $Q$-function. The $Q$-function to be learned should be initialized using `qinit`. \n",
    "\n",
    "Note that, at each step of the interaction,\n",
    "\n",
    "* The agent should observe the current state, and select an action using an $\\epsilon$-greedy policy with respect to its current estimate of the optimal $Q$-values. You should use the function `egreedy` from Activity 2, with $\\epsilon=0.15$. \n",
    "* Given the state and action, you must then compute the cost and generate the next state, using `mdp` and the function `sample_transition` from Activity 1.\n",
    "* With this transition information (state, action, cost, next-state), you can now perform an update to the $Q$-function.\n",
    "* When updating the components $(x,a)$ of the model, use the step-size $\\alpha=0.3$.\n",
    "\n",
    "Your function should return a `numpy` array with as many rows as the number of states in `mdp` and as many columns as the number of actions in `mdp`, corresponding to the learned $Q$-function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T09:18:48.576851Z",
     "start_time": "2019-12-09T09:18:48.571201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here.\n",
    "def qlearning(mdp, n, qinit):\n",
    "        \n",
    "    gamma = mdp[-1]\n",
    "    alfa = 0.3\n",
    "    \n",
    "    numstates = len(mdp[0])\n",
    "    numactions = len(mdp[1])\n",
    "    \n",
    "    # select at random the initial state (time step t = 0)\n",
    "    s = rnd.choice(numstates)\n",
    "    \n",
    "    # simulates an interaction of n steps between the agent and the environment\n",
    "    for t in range(n):\n",
    "        \n",
    "        # given the current state, select an action using an ðœ–-greedy policy with respect to \n",
    "        # its current estimate of the optimal ð‘„-values\n",
    "        a = egreedy(qinit[s,:], 0.15) \n",
    "        \n",
    " \n",
    "        # compute the cost and generate the next state\n",
    "        transition = sample_transition(mdp, s, a)\n",
    "        \n",
    "        # cost in time step t\n",
    "        c = transition[2]\n",
    "        \n",
    "        # state in time step t + 1\n",
    "        s_next = transition[3]\n",
    "        \n",
    "        \n",
    "        # perform an update to the ð‘„-function    \n",
    "        qinit[s,a] += alfa*(c + gamma*np.min(qinit[s_next,:])-qinit[s,a])\n",
    "        \n",
    "        # update the current state for the next iteration\n",
    "        s = s_next \n",
    "        \n",
    "    return qinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Q after 1000 steps: 19.944334092242844\n",
      "Error in Q after 2000 steps: 19.91105731381223\n"
     ]
    }
   ],
   "source": [
    "rnd.seed(42)\n",
    "\n",
    "# Initialize Q-function\n",
    "qinit = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "# Run 1000 steps of model-based learning\n",
    "qnew = qlearning(M, 1000, qinit)\n",
    "\n",
    "# Compare the learned Q with the optimal Q\n",
    "print('Error in Q after 1000 steps:', np.linalg.norm(qnew - Qopt))\n",
    "\n",
    "# Run 1000 additional steps of model-based learning\n",
    "qnew = qlearning(M, 1000, qnew)\n",
    "\n",
    "# Compare once again the learned Q with the optimal Q\n",
    "print('Error in Q after 2000 steps:', np.linalg.norm(qnew - Qopt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T09:18:48.567188Z",
     "start_time": "2019-12-09T09:18:48.333226Z"
    },
    "scrolled": false
   },
   "source": [
    "As an example using the \"Pacman\" MDP, we could run:\n",
    "\n",
    "```python\n",
    "rnd.seed(42)\n",
    "\n",
    "# Initialize Q-function\n",
    "qinit = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "# Run 1000 steps of model-based learning\n",
    "qnew = qlearning(M, 1000, qinit)\n",
    "\n",
    "# Compare the learned Q with the optimal Q\n",
    "print('Error in Q after 1000 steps:', np.linalg.norm(qnew - Qopt))\n",
    "\n",
    "# Run 1000 additional steps of model-based learning\n",
    "qnew = qlearning(M, 1000, qnew)\n",
    "\n",
    "# Compare once again the learned Q with the optimal Q\n",
    "print('Error in Q after 2000 steps:', np.linalg.norm(qnew - Qopt))\n",
    "```\n",
    "\n",
    "to get\n",
    "\n",
    "```\n",
    "Error in Q after 1000 steps: 19.944334092242844\n",
    "Error in Q after 2000 steps: 19.91105731381223\n",
    "```\n",
    "\n",
    "Once again, even if the seed is fixed, the numerical values may differ somewhat from those above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 5. \n",
    "\n",
    "Write a function `sarsa` that implements the SARSA algorithm discussed in class. Your function should receive as input arguments \n",
    "\n",
    "* A tuple, `mdp`, containing the description of an **arbitrary** MDP. The structure of the tuple is similar to that provided in the examples above. \n",
    "* An integer, `n`, corresponding he number of steps that your algorithm should run.\n",
    "*  A `numpy` array `qinit` with as many rows as the number of states in `mdp` and as many columns as the number of actions in `mdp`. The matrix `qinit` should be used to initialize the $Q$-function being learned by your function.\n",
    "\n",
    "Your function should simulate an interaction of `n` steps between the agent and the environment, during which it should perform `n` iterations of the SARSA algorithm seen in class. The $Q$-function to be learned should be initialized using `qinit`. \n",
    "\n",
    "Note that, at each step of the interaction,\n",
    "\n",
    "* The agent should observe the current state, and select an action using an $\\epsilon$-greedy policy with respect to its current estimate of the optimal $Q$-values. You should use the function `egreedy` from Activity 2, with $\\epsilon=0.15$. **Do not adjust the value of $\\epsilon$ during learning.**\n",
    "* Given the state and action, you must then compute the cost and generate the next state, using `mdp` and the function `sample_transition` from Activity 1.\n",
    "* With this transition information (state, action, cost, next-state), you can now perform an update to the $Q$-function.\n",
    "* When updating the components $(x,a)$ of the model, use the step-size $\\alpha=0.3$.\n",
    "\n",
    "Your function should return a `numpy` array with as many rows as the number of states in `mdp` and as many columns as the number of actions in `mdp`, corresponding to the learned $Q$-function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T09:18:48.771464Z",
     "start_time": "2019-12-09T09:18:48.766170Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here.\n",
    "def sarsa(mdp, n, qinit):\n",
    "\n",
    "    gamma = mdp[-1]\n",
    "    alfa = 0.3\n",
    "    \n",
    "    numstates = len(mdp[0])\n",
    "    numactions = len(mdp[1])\n",
    "    \n",
    "    # select at random the initial state (time step t = 0)\n",
    "    s = rnd.choice(numstates)\n",
    "\n",
    "    # given the current state, select an action using an ðœ–-greedy policy with respect to \n",
    "    # its current estimate of the optimal ð‘„-values\n",
    "    a = egreedy(qinit[s,:], 0.15) \n",
    "    \n",
    "    for t in range(n):\n",
    "        \n",
    "        # compute the cost and generate the next state\n",
    "        transition = sample_transition(mdp, s, a)\n",
    "        \n",
    "        # cost in time step t\n",
    "        c = transition[2]\n",
    "        \n",
    "        # state in time step t + 1\n",
    "        s_next = transition[3]\n",
    "        \n",
    "        # given the current state, select an action using an ðœ–-greedy policy with respect to \n",
    "        # its current estimate of the optimal ð‘„-values\n",
    "        a_next = egreedy(qinit[s_next,:], 0.15)\n",
    "        \n",
    "        # perform an update to the ð‘„-function    \n",
    "        qinit[s,a] += alfa*(c + gamma*qinit[s_next,a_next]-qinit[s,a])\n",
    "        \n",
    "        # update the current state for the next iteration\n",
    "        s = s_next \n",
    "        \n",
    "        # update the current action for the next iteration\n",
    "        a = a_next \n",
    "        \n",
    "    return qinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Q after 1000 steps: 19.944134856701385\n",
      "Error in Q after 2000 steps: 19.91302892958602\n"
     ]
    }
   ],
   "source": [
    "rnd.seed(42)\n",
    "\n",
    "# Initialize Q-function\n",
    "qinit = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "# Run 1000 steps of model-based learning\n",
    "qnew = sarsa(M, 1000, qinit)\n",
    "\n",
    "# Compare the learned Q with the optimal Q\n",
    "print('Error in Q after 1000 steps:', np.linalg.norm(qnew - Qopt))\n",
    "\n",
    "# Run 1000 additional steps of model-based learning\n",
    "qnew = sarsa(M, 1000, qnew)\n",
    "\n",
    "# Compare once again the learned Q with the optimal Q\n",
    "print('Error in Q after 2000 steps:', np.linalg.norm(qnew - Qopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:37<00:00,  3.75s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error in $Q$-function')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "STEPS = 10\n",
    "ITERS = 1000\n",
    "RUNS  = 10\n",
    "\n",
    "iters = range(0, STEPS * ITERS + 1, STEPS)\n",
    "\n",
    "# Error matrices\n",
    "Emb = np.zeros(ITERS + 1)\n",
    "Eql = np.zeros(ITERS + 1)\n",
    "Ess = np.zeros(ITERS + 1)\n",
    "\n",
    "Emb[0] = np.linalg.norm(Qopt) * RUNS\n",
    "Eql[0] = Emb[0]\n",
    "Ess[0] = Emb[0]\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "for n in trange(RUNS):\n",
    "\n",
    "    # Initialization\n",
    "    pmb = ()\n",
    "    for a in range(len(M[1])):\n",
    "        pmb += (np.eye(len(M[0])),)\n",
    "    cmb = np.zeros((len(M[0]), len(M[1])))\n",
    "    qmb = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "    qql = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "    qss = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "    # Run evaluation\n",
    "    for t in range(ITERS):\n",
    "        qmb, pmb, cmb = mb_learning(M, STEPS, qmb, pmb, cmb)\n",
    "        Emb[t + 1] += np.linalg.norm(Qopt - qmb)\n",
    "\n",
    "        qql = qlearning(M, STEPS, qql)\n",
    "        Eql[t + 1] += np.linalg.norm(Qopt - qql)\n",
    "\n",
    "        qss = sarsa(M, STEPS, qss)\n",
    "        Ess[t + 1] += np.linalg.norm(Qopt - qss)\n",
    "\n",
    "Emb /= RUNS\n",
    "Eql /= RUNS\n",
    "Ess /= RUNS\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(iters, Emb, label='Model based learning')\n",
    "plt.plot(iters, Eql, label='Q-learning')\n",
    "plt.plot(iters, Ess, label='SARSA')\n",
    "plt.legend()\n",
    "plt.xlabel('N. iterations')\n",
    "plt.ylabel('Error in $Q$-function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:53<00:00, 41.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error in $Q$-function')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "STEPS = 10\n",
    "ITERS = 10000\n",
    "RUNS  = 10\n",
    "\n",
    "iters = range(0, STEPS * ITERS + 1, STEPS)\n",
    "\n",
    "# Error matrices\n",
    "Emb = np.zeros(ITERS + 1)\n",
    "Eql = np.zeros(ITERS + 1)\n",
    "Ess = np.zeros(ITERS + 1)\n",
    "\n",
    "Emb[0] = np.linalg.norm(Qopt) * RUNS\n",
    "Eql[0] = Emb[0]\n",
    "Ess[0] = Emb[0]\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "for n in trange(RUNS):\n",
    "\n",
    "    # Initialization\n",
    "    pmb = ()\n",
    "    for a in range(len(M[1])):\n",
    "        pmb += (np.eye(len(M[0])),)\n",
    "    cmb = np.zeros((len(M[0]), len(M[1])))\n",
    "    qmb = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "    qql = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "    qss = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "    # Run evaluation\n",
    "    for t in range(ITERS):\n",
    "        qmb, pmb, cmb = mb_learning(M, STEPS, qmb, pmb, cmb)\n",
    "        Emb[t + 1] += np.linalg.norm(Qopt - qmb)\n",
    "\n",
    "        qql = qlearning(M, STEPS, qql)\n",
    "        Eql[t + 1] += np.linalg.norm(Qopt - qql)\n",
    "\n",
    "        qss = sarsa(M, STEPS, qss)\n",
    "        Ess[t + 1] += np.linalg.norm(Qopt - qss)\n",
    "\n",
    "Emb /= RUNS\n",
    "Eql /= RUNS\n",
    "Ess /= RUNS\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(iters, Emb, label='Model based learning')\n",
    "plt.plot(iters, Eql, label='Q-learning')\n",
    "plt.plot(iters, Ess, label='SARSA')\n",
    "plt.legend()\n",
    "plt.xlabel('N. iterations')\n",
    "plt.ylabel('Error in $Q$-function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T09:18:48.567188Z",
     "start_time": "2019-12-09T09:18:48.333226Z"
    },
    "scrolled": false
   },
   "source": [
    "As an example using the \"Pacman\" MDP, we could run:\n",
    "\n",
    "```python\n",
    "rnd.seed(42)\n",
    "\n",
    "# Initialize Q-function\n",
    "qinit = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "# Run 1000 steps of model-based learning\n",
    "qnew = sarsa(M, 1000, qinit)\n",
    "\n",
    "# Compare the learned Q with the optimal Q\n",
    "print('Error in Q after 1000 steps:', np.linalg.norm(qnew - Qopt))\n",
    "\n",
    "# Run 1000 additional steps of model-based learning\n",
    "qnew = sarsa(M, 1000, qnew)\n",
    "\n",
    "# Compare once again the learned Q with the optimal Q\n",
    "print('Error in Q after 2000 steps:', np.linalg.norm(qnew - Qopt))\n",
    "```\n",
    "\n",
    "to get\n",
    "\n",
    "```\n",
    "Error in Q after 1000 steps: 19.944134856701385\n",
    "Error in Q after 2000 steps: 19.91302892958602\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run the following code, to compare the performance of the three methods.\n",
    "\n",
    "```python\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "STEPS = 10\n",
    "ITERS = 1000\n",
    "RUNS  = 10\n",
    "\n",
    "iters = range(0, STEPS * ITERS + 1, STEPS)\n",
    "\n",
    "# Error matrices\n",
    "Emb = np.zeros(ITERS + 1)\n",
    "Eql = np.zeros(ITERS + 1)\n",
    "Ess = np.zeros(ITERS + 1)\n",
    "\n",
    "Emb[0] = np.linalg.norm(Qopt) * RUNS\n",
    "Eql[0] = Emb[0]\n",
    "Ess[0] = Emb[0]\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "for n in trange(RUNS):\n",
    "\n",
    "    # Initialization\n",
    "    pmb = ()\n",
    "    for a in range(len(M[1])):\n",
    "        pmb += (np.eye(len(M[0])),)\n",
    "    cmb = np.zeros((len(M[0]), len(M[1])))\n",
    "    qmb = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "    qql = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "    qss = np.zeros((len(M[0]), len(M[1])))\n",
    "\n",
    "    # Run evaluation\n",
    "    for t in range(ITERS):\n",
    "        qmb, pmb, cmb = mb_learning(M, STEPS, qmb, pmb, cmb)\n",
    "        Emb[t + 1] += np.linalg.norm(Qopt - qmb)\n",
    "\n",
    "        qql = qlearning(M, STEPS, qql)\n",
    "        Eql[t + 1] += np.linalg.norm(Qopt - qql)\n",
    "\n",
    "        qss = sarsa(M, STEPS, qss)\n",
    "        Ess[t + 1] += np.linalg.norm(Qopt - qss)\n",
    "        \n",
    "Emb /= RUNS\n",
    "Eql /= RUNS\n",
    "Ess /= RUNS\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(iters, Emb, label='Model based learning')\n",
    "plt.plot(iters, Eql, label='Q-learning')\n",
    "plt.plot(iters, Ess, label='SARSA')\n",
    "plt.legend()\n",
    "plt.xlabel('N. iterations')\n",
    "plt.ylabel('Error in $Q$-function')\n",
    "```\n",
    "\n",
    "As the output, you should observe a plot similar to the one below.\n",
    "\n",
    "<img src=\"plot.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 6.\n",
    "\n",
    "**Based on the results you obtained when running the above code with your algorithms**, discuss the differences observed between the performance of the three methods.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Insert your comments here.</span>\n",
    "\n",
    "As can be seen, the performance of the model based method corresponds to the best of the three, taking into consideration the criteria of the error in the Q function (in relation to the optimal Q function) learned along iterations. The graphic shows that it is the one which more rapidly converges to the correct MDP (and hence the optimal Q function), being expected to do so if enough samples of each state are analysed, that is, if every action is experimented many times in every state. Indeed, these model based methods try to learn a model for the MDP (estimate the cost function and transition probabilities) from the experience that the agent has while interacting with the environment. In this case, the optimal Q function is learned by applying the value iteration algorithm for MDPs. This inner understanding of the system dynamics reduces the number of the samples required for learning (most sample efficient), thus its faster converge to the optimal Q-function regarding the number of iterations taken. \n",
    "\n",
    "In contrast, the Q-learning and SARSA algorithms allow to select actions without a model of the MDP. Although, the lesser the information about the model, the more trial and error is needed to compute the optimal Q-function, that is, more samples need to be acquired, thus more iterations are needed for converge to the optimal Q-function. \n",
    "\n",
    "Comparing Q-learning and SARSA, for ITERS = 1000 their performance is pratically the same. Altought, when setting ITERS = 10000, it is clearly seen that the SARSA diverges from the optimal Q-function, and the Q-learning converges to the optimal Q-function. This is due to the fact that the SARSA algorithm implemented doesn't  perform policy improvement (for example, ðœ€-greedy with decaying ðœ€), in order to make sure that the policy that the agent is following slowly approaches a greedy policy. In fact, off-policy methods (being Q-learning an example) learn the value of one policy (optimal policy) while following another, being guaranteed the converge to the optimal Q-function if enought exploration is undertaken (tunable by the ðœ€ parameter). As for on-policy methods (being SARSA an example), they learn the value of the policy that it follows, computing the Q-values for its current policy, being not guaranteed that it will converge to the optimal Q. \n",
    "\n",
    "Nevertheless, as more knowledge is available, suboptimal actions become less interesting, approaching the optimal Q-function, which was observed in the performances of the three algorithms. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
