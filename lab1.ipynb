{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratory 1: Markov chains\n",
    "\n",
    "In the end of the lab, you should export the notebook to a Python script (File >> Download as >> Python (.py)). Your file should be named `padi-lab1-groupXX.py`, where the `XX` corresponds to your group number and should be submitted to the e-mail <adi.tecnico@gmail.com>. \n",
    "\n",
    "Make sure...\n",
    "\n",
    "* **... that the subject is of the form `[<group n.>] LAB <lab n.>`.** \n",
    "\n",
    "* **... to strictly respect the specifications in each activity, in terms of the intended inputs, outputs and naming conventions.** \n",
    "\n",
    "In particular, after completing the activities you should be able to replicate the examples provided (although this, in itself, is no guarantee that the activities are correctly completed).\n",
    "\n",
    "### 1. The Markov chain model\n",
    "\n",
    "Consider once again the Pacman modeling problem described in the Homework and for which you wrote a Markov chain model. In this lab, you will consider a larger version of the Pacman problem, described by the diagram:\n",
    "\n",
    "<img src=\"pacman-big.png\">\n",
    "\n",
    "Recall that your chain should describe the motion of the single ghost moving in the environment, where: \n",
    "\n",
    "* The cells are numbered from 1 to 35, as indicated by the blue numbers;\n",
    "* At each moment, the ghost is in one of the 35 cells; at the next time step, it will move to one of the adjacent cells with equal probability;\n",
    "* The cell in the bottom left corner (cell `29`) is adjacent, to the left, to the cell in the bottom right corner (cell `35`). In other words, if the ghost \"moves left\" in cell `29` it will end up in cell `35` and vice-versa.\n",
    "\n",
    "In this first activity, you will implement your Markov chain model in Python. You will start by loading the transition probability matrix from a `numpy` binary file, using the `numpy` function `load`. You will then consider the state space to consist of all possible cells in the environment, each represented as a string. For example, if the environment has 10 cells, the states should include the strings `'1'` to `'10'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 1.        \n",
    "\n",
    "Write a function named `load_chain` that receives, as input, a string corresponding to the name of a file containing a transition probability matrix for some Pacman maze to be loaded and returns, as output, a two-element tuple corresponding to the Markov chain that describes the movement of the ghost, where:\n",
    "\n",
    "* ... the first element is a tuple containing an enumeration of the state-space (i.e., each element of the tuple corresponds to a state of the chain, represented as a string).\n",
    "* ... the second element is a `numpy` array corresponding to the transition probability matrix for the chain.\n",
    "\n",
    "**Note:** The file provided contains the transition probability matrix for the maze in the diagram above. However, your code will be tested with mazes of different sizes, so **make sure not to hard-code the size of the environment into your code**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:25:18.819450Z",
     "start_time": "2022-03-09T15:25:14.782973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here.\n",
    "import numpy as np\n",
    "\n",
    "def load_chain(P_file):\n",
    "    P = np.load(P_file)\n",
    "    \n",
    "    states = () # create an empty tuple\n",
    "    \n",
    "    for i in range(1,P.shape[1]+1):\n",
    "        states += (str(i),)\n",
    "            \n",
    "    M = (states, P)\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35')\n",
      "Number of states: 35\n",
      "Type of states: <class 'str'>\n",
      "First state: 1\n",
      "\n",
      "Transition probability matrix (type): <class 'numpy.ndarray'>\n",
      "Transition probability matrix (dimension): (35, 35)\n"
     ]
    }
   ],
   "source": [
    "M = load_chain('pacman-big.npy')\n",
    "\n",
    "print(M[0])\n",
    "print('Number of states:', len(M[0]))\n",
    "print('Type of states:', type(M[0][0]))\n",
    "print('First state:', M[0][0])\n",
    "print('\\nTransition probability matrix (type):', type(M[1]))\n",
    "print('Transition probability matrix (dimension):', M[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide below an example of application of the function, that you can use as a first \"sanity check\" for your code. Note, however, that the fact that you can replicate the examples below is not indicative that your code is correct.\n",
    "\n",
    "```python\n",
    "M = load_chain('pacman-big.npy')\n",
    "\n",
    "print('Number of states:', len(M[0]))\n",
    "print('Type of states:', type(M[0][0]))\n",
    "print('First state:', M[0][0])\n",
    "print('\\nTransition probability matrix (type):', type(M[1]))\n",
    "print('Transition probability matrix (dimension):', M[1].shape)```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Number of states: 35\n",
    "Type of states: <class 'str'>\n",
    "First state: 1\n",
    "\n",
    "Transition probability matrix (type): <class 'numpy.ndarray'>\n",
    "Transition probability matrix (dimension): (35, 35)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next activity, you will use the Markov chain model to evaluate the likelihood of any given path for the ghost.\n",
    "\n",
    "---\n",
    "\n",
    "#### Activity 2.\n",
    "\n",
    "Write a function `prob_trajectory` that receives, as inputs, \n",
    "\n",
    "* ... a Markov chain in the form of a tuple like the one returned by the function in Activity 1;\n",
    "* ... a trajectory, corresponding to a sequence of states (i.e., a tuple or list of strings, each string corresponding to a state).\n",
    "\n",
    "Your function should return, as output, a floating point number corresponding to the probability of observing the provided trajectory, taking the first state in the trajectory as initial state. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:40:07.912333Z",
     "start_time": "2020-09-24T17:40:07.904515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here.\n",
    "def prob_trajectory(M, seq_states):\n",
    "    \n",
    "    #we wish to find the probability of the trajectory seq_states = s0, s1, s2, ..., st, given by the probability: \n",
    "    #P(x0 = s0, x1 = s1, ..., xt = st) = \n",
    "    #P(xt = st | xt-1 = st-1, ..., x0 = s0) * P(xt-1 = st-1, ..., x0 = s0) = \n",
    "    #P(xt = st | xt-1 = st-1) * P(xt-1 = st-1, ..., x0) (markov property)\n",
    "    \n",
    "    #Because of the Markov Property, we can find the probability of any trajectory by multiplying together the \n",
    "    #starting probability and all subsequent single-step probabilities.\n",
    "    \n",
    "    # initialization of the variable that represents the joint probability of observing the states that form the \n",
    "    # provided trajectory, being assigned the starting probability which takes the value of 1.0 (floating point \n",
    "    # number as required), since it is assumed the first state in the trajectory as initial state\n",
    "    p = 1.0; \n",
    "    \n",
    "    #iteration over the provided trajectory, starting from index 1 \n",
    "    for i in range(1, len(seq_states)):\n",
    "        \n",
    "        index1 = M[0].index(seq_states[i-1]) #last state\n",
    "        index2 = M[0].index(seq_states[i]) #present state \n",
    "        \n",
    "        \n",
    "        p = p*M[1][index1, index2] #1-step transition given the last observed state \n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of trajectory ('3', '9', '15'): 0.16666666666666666\n",
      "Prob. of trajectory ('6', '7', '12', '11', '10'): 0.0625\n",
      "Prob. of trajectory ('10', '11', '17'): 0.0\n",
      "Prob. of trajectory ('34', '35', '29'): 0.25\n"
     ]
    }
   ],
   "source": [
    "print(\"Prob. of trajectory ('3', '9', '15'):\", prob_trajectory(M, ('3', '9', '15')))\n",
    "print(\"Prob. of trajectory ('6', '7', '12', '11', '10'):\", prob_trajectory(M, ('6', '7', '12', '11', '10')))\n",
    "print(\"Prob. of trajectory ('10', '11', '17'):\", prob_trajectory(M, ('10', '11', '17')))\n",
    "print(\"Prob. of trajectory ('34', '35', '29'):\", prob_trajectory(M, ('34', '35', '29')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of application of the function with the chain $M$ from Activity 1.\n",
    "\n",
    "```python\n",
    "print(\"Prob. of trajectory ('3', '9', '15'):\", prob_trajectory(M, ('3', '9', '15')))\n",
    "print(\"Prob. of trajectory ('6', '7', '12', '11', '10'):\", prob_trajectory(M, ('6', '7', '12', '11', '10')))\n",
    "print(\"Prob. of trajectory ('10', '11', '17'):\", prob_trajectory(M, ('10', '11', '17')))\n",
    "print(\"Prob. of trajectory ('34', '35', '29'):\", prob_trajectory(M, ('34', '35', '29')))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Prob. of trajectory ('3', '9', '15'): 0.16666666666666666\n",
    "Prob. of trajectory ('6', '7', '12', '11', '10'): 0.0625\n",
    "Prob. of trajectory ('10', '11', '17'): 0.0\n",
    "Prob. of trajectory ('34', '35', '29'): 0.25\n",
    "```\n",
    "\n",
    "Note that your function should work with **any** Markov chain that is specified as a tuple like the one from Activity 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next activities explore the notion of *stationary distribution* for the chain, a central concept in the the PageRank algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "#### Activity 3\n",
    "\n",
    "Write a function `stationary_dist` that receives, as input, a Markov chain in the form of a tuple like the one returned by the function in Activity 1. Your function should return, as output, a `numpy` array corresponding to a row vector containing the stationary distribution for the chain.\n",
    "\n",
    "**Note:** The stationary distribution is a *left* eigenvector of the transition probability matrix associated to the eigenvalue 1. As such, you may find useful the numpy function `numpy.linalg.eig`. Also, recall that the stationary distribution is *a distribution*.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:41:48.907805Z",
     "start_time": "2020-09-24T17:41:48.892401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here.\n",
    "def stationary_dist(M):\n",
    "    \n",
    "    #From the equation of stationarity uP=u, u must be a left eigenvector of P with eigenvalue 1.\n",
    "    #np.linalg.eig returns the right eigenvectors, but the left eighenvector of a matrix is the right eigenvector \n",
    "    #of the transposed matrix.\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(M[1].T) \n",
    "    idx = np.isclose(eigenvalues, 1) # find index of eigenvalue = 1\n",
    "    eigenvectors1 = eigenvectors[:,idx] # Left eigenvector with eigenvalue 1\n",
    "    \n",
    "    # normalize eigenvector to get a probability distribution (the sum of the probabilities must be exactly 1)\n",
    "    stationary = eigenvectors1 / eigenvectors1.sum()\n",
    "    \n",
    "    # np.linalg.eig finds complex eigenvalues and eigenvectors, being only relevant the real part\n",
    "    stationary = stationary.real\n",
    "\n",
    "    return (stationary.T).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stationary distribution:\n",
      "[0.03 0.03 0.05 0.03 0.03 0.03 0.03 0.04 0.03 0.03 0.03 0.03 0.05 0.03\n",
      " 0.07 0.03 0.04 0.03 0.03 0.04 0.04 0.05 0.03 0.02 0.02 0.02 0.02 0.02\n",
      " 0.01 0.   0.   0.01 0.01 0.01 0.01]\n",
      "\n",
      "Is u* * P = u*? True\n"
     ]
    }
   ],
   "source": [
    "u_star = stationary_dist(M)\n",
    "\n",
    "print('Stationary distribution:')\n",
    "print(np.round(u_star, 2))\n",
    "\n",
    "u_prime = u_star.dot(M[1])\n",
    "\n",
    "print('\\nIs u* * P = u*?', np.all(np.isclose(u_prime, u_star)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of application of the function with the chain $M$ from Activity 1.\n",
    "\n",
    "```python\n",
    "u_star = stationary_dist(M)\n",
    "\n",
    "print('Stationary distribution:')\n",
    "print(np.round(u_star, 2))\n",
    "\n",
    "u_prime = u_star.dot(M[1])\n",
    "\n",
    "print('\\nIs u* * P = u*?', np.all(np.isclose(u_prime, u_star)))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Stationary distribution:\n",
    "[0.03 0.03 0.05 0.03 0.03 0.03 0.03 0.04 0.03 0.03 0.03 0.03 0.05 0.03\n",
    " 0.07 0.03 0.04 0.03 0.03 0.04 0.04 0.05 0.03 0.02 0.02 0.02 0.02 0.02\n",
    " 0.01 0.   0.   0.01 0.01 0.01 0.01]\n",
    "\n",
    "Is u* * P = u*? True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complement Activity 3, you will now empirically establish that the chain is ergodic, i.e., no matter where the ghost starts, its visitation frequency will eventually converge to the stationary distribution.\n",
    "\n",
    "---\n",
    "\n",
    "#### Activity 4.\n",
    "\n",
    "Write a function `compute_dist` that receives, as inputs, \n",
    "\n",
    "* ... a Markov chain in the form of a tuple like the one returned by the function in Activity 1;\n",
    "* ... a row vector (a numpy array) corresponding to the initial distribution for the chain;\n",
    "* ... an integer $N$, corresponding to the number of steps that the bot is expected to take.\n",
    "\n",
    "Your function should return, as output, a row vector (a `numpy` array) containing the distribution after $N$ steps of the chain.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:42:29.107319Z",
     "start_time": "2020-09-24T17:42:29.099857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here.\n",
    "def compute_dist(M, u0, N):\n",
    "    \n",
    "    # Raising the matrix P to the Nth power, denoting the N-step transition probabilities\n",
    "    P_tstep = np.linalg.matrix_power(M[1], N)\n",
    "    \n",
    "    # distribution probability of an N-step transition, given the initial distribution u0 \n",
    "    u = np.dot(u0, P_tstep) \n",
    "\n",
    "    return u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Is u * P^100 = u*? False\n",
      "\n",
      "Is u * P^2000 = u*? True\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as rnd\n",
    "\n",
    "# Number of states\n",
    "nS = len(M[0])\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "# Initial random distribution\n",
    "u = rnd.random((1, nS))\n",
    "u = u / np.sum(u)\n",
    "\n",
    "# Distrbution after 100 steps\n",
    "v = compute_dist(M, u, 100)\n",
    "print('\\nIs u * P^100 = u*?', np.all(np.isclose(v, u_star)))\n",
    "\n",
    "# Distrbution after 2000 steps\n",
    "v = compute_dist(M, u, 2000)\n",
    "print('\\nIs u * P^2000 = u*?', np.all(np.isclose(v, u_star)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of application of the function with the chain $M$ from Activity 1.\n",
    "\n",
    "```python\n",
    "import numpy.random as rnd\n",
    "\n",
    "# Number of states\n",
    "nS = len(M[0])\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "# Initial random distribution\n",
    "u = rnd.random((1, nS))\n",
    "u = u / np.sum(u)\n",
    "\n",
    "# Distrbution after 100 steps\n",
    "v = compute_dist(M, u, 100)\n",
    "print('\\nIs u * P^100 = u*?', np.all(np.isclose(v, u_star)))\n",
    "\n",
    "# Distrbution after 2000 steps\n",
    "v = compute_dist(M, u, 2000)\n",
    "print('\\nIs u * P^2000 = u*?', np.all(np.isclose(v, u_star)))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Is u * P^100 = u*? False\n",
    "\n",
    "Is u * P^2000 = u*? True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the chain ergodic? Justify, based on the results above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit this cell and insert your answer here (you can delete this line).\n",
    "\n",
    "In this last activity, an iterative approach is adopted in order to empirically verify if the Markov Chain is converging to some probability distribution $$\\mu^{*} = \\mu_0.P^{n}, {n\\to\\infty}$$, with $\\mu_0$ being the initial distribution and $\\mu^{*}$ the stationary distribution (computed in the activity 3).\n",
    "\n",
    "As was demonstrated by the applied examples, namely when $n = 2000$, in fact this markov chain converges to its stationary distribution, hence the chain is ergodic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simulation\n",
    "\n",
    "In this part of the lab, you will *simulate* the actual bot, and empirically compute the visitation frequency of each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 5\n",
    "\n",
    "Write down a function `simulate` that receives, as inputs, \n",
    "\n",
    "* ... a Markov chain in the form of a tuple like the one returned by the function in Activity 1;\n",
    "* ... a row vector (a `numpy` array) corresponding to the initial distribution for the chain;\n",
    "* ... an integer $N$, corresponding to the number of steps that the bot is expected to take.\n",
    "\n",
    "Your function should return, as output, a tuple containing a trajectory containing $N$ states, obtained from the initial distribution provided. Each element in the tuple should be a string corresponding to a state index.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** You may find useful to import the numpy module `numpy.random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:43:39.189231Z",
     "start_time": "2020-09-24T17:43:38.832378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here.\n",
    "import numpy.random as rnd\n",
    "\n",
    "def simulate(M, u0, N):\n",
    "    \n",
    "    # generate initial state, by considering the initial probability distribution\n",
    "    x0 = rnd.choice(M[0], p = u0[0,:])\n",
    "    \n",
    "    # simulate:\n",
    "    X = (x0,) # initiate the variable that represents the trajectory, being assigned the first generated state\n",
    "\n",
    "    # iterate over the remaining N-1 number of steps that the bot is expected to take\n",
    "    for t in range(N-1):\n",
    "        \n",
    "        xt = M[0].index(X[t])\n",
    "        \n",
    "        # generate state at step t+1, by considering the probability distribution P(Xt+1| Xt = xt) \n",
    "        xt1 = rnd.choice(M[0], p = (M[1][xt,:]))\n",
    "        \n",
    "        #adding the present generated state to the trajectory \n",
    "        X += (xt1, )\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small trajectory: ('14', '15', '16', '17', '10', '11', '10', '17', '16', '17')\n",
      "End of large trajectory: ('13', '8', '1', '8', '1', '8', '1', '8', '13', '20')\n"
     ]
    }
   ],
   "source": [
    "# Number of states\n",
    "nS = len(M[0])\n",
    "\n",
    "# Initial, uniform distribution\n",
    "u = np.ones((1, nS)) / nS\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate short trajectory\n",
    "traj = simulate(M, u, 10)\n",
    "print('Small trajectory:', traj)\n",
    "\n",
    "# Simulate a long trajectory\n",
    "traj = simulate(M, u, 10000)\n",
    "print('End of large trajectory:', traj[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of application of the function with the chain $M$ from Activity 1.\n",
    "\n",
    "```python\n",
    "# Number of states\n",
    "nS = len(M[0])\n",
    "\n",
    "# Initial, uniform distribution\n",
    "u = np.ones((1, nS)) / nS\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate short trajectory\n",
    "traj = simulate(M, u, 10)\n",
    "print('Small trajectory:', traj)\n",
    "\n",
    "# Simulate a long trajectory\n",
    "traj = simulate(M, u, 10000)\n",
    "print('End of large trajectory:', traj[-10:])\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Small trajectory: ('14', '15', '16', '17', '10', '11', '10', '17', '16', '17')\n",
    "End of large trajectory: ('13', '8', '1', '8', '1', '8', '1', '8', '13', '20')\n",
    "```\n",
    "\n",
    "Note that, even if the seed is fixed, it is possible that your trajectories are slightly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 6\n",
    "\n",
    "Use the function `simulate` from Activity #5 to generate a 20,000-step trajectory. Plot the histogram of the obtained trajectory using the function `hist` from the module `matplotlib.pyplot`. Make sure that the histogram has one bin for each state. Compare the relative frequencies with the result of Activity #3.\n",
    "\n",
    "**Note**: Don't forget to load `matplotlib`. \n",
    "\n",
    "**Note 2**: Recall that the states in the trajectory obtained from the function `simulate` consist of *strings*, which should be converted to state indices to match the entries in the distribution computed in Activity #3.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:47:06.647350Z",
     "start_time": "2020-09-24T17:47:06.168651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert your code here.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nsteps = 20000\n",
    "\n",
    "#np.random.seed(42) \n",
    "\n",
    "traj = simulate(M, u, nsteps)\n",
    "\n",
    "# initialize the array that will contain in each entry the state indices matching \n",
    "# the entries in the distribution computed in Activity #3 \n",
    "traj_indices = np.zeros((1,nsteps)) \n",
    "\n",
    "#iterate over the trajectory\n",
    "for i in range(0, nsteps):\n",
    "    traj_indices[0,i] = int(traj[i])\n",
    "\n",
    "# array of bin edges, giving one bin for each state, containing values from [left_edge, right_edge), \n",
    "# that is, it includes the left edge and excludes the right one. The last bin contains the values [left_edge, right_edge]\n",
    "bins = np.arange(1,len(M[0])+2) - 0.5\n",
    "\n",
    "# Plot commands\n",
    "\n",
    "# creating histogram. note that density=False would make counts. setting density=True, \n",
    "# P is the probability distribution of the Markov chain at time nsteps (= 20000 for this specific exercise)\n",
    "P, bins, pacthes = plt.hist(traj_indices[0,:], bins=bins, density = True, rwidth = 0.5) \n",
    "\n",
    "plt.plot(range(1,len(M[0])+1), u_star, '*k')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Relative Frequencies')\n",
    "plt.title(f\"{nsteps} time steps\",\n",
    "          fontweight =\"bold\")\n",
    "  \n",
    "plt.show() # Show plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the relative frequencies after 20000 steps are similar to the ones given by the stationary distribution. If more steps were taken, this relative frequncies would converge even more to the stationary distribution, because of its ergodic behaviour. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
